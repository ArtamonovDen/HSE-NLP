{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14df467c-3619-4e41-aed6-99529ebc1d47",
   "metadata": {},
   "source": [
    "# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ2: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618d0a6-efcc-4c41-8f72-39e803c26a06",
   "metadata": {},
   "source": [
    "**–í—ã–ø–æ–ª–Ω–∏–ª: –ê—Ä—Ç–∞–º–æ–Ω–æ–≤ –î.–°, 20 –ú–ê–ì –ò–ê–î**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a798bad6-75ba-4ccb-99d8-76515fa18efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torchtext.datasets import SequenceTaggingDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00ef20-1aca-4e37-983b-779248379e49",
   "metadata": {},
   "source": [
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤—Ö–æ–¥—è—Ç –≤ `requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565cd23-64c7-48bd-af74-fe5c26c123e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext==0.6.0 nerus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8459f1-def8-4d53-b992-a502105f74c8",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [Nerus](https://github.com/natasha/nerus) - –ø–æ—á—Ç–∏ 700–∫ —Å—Ç–∞—Ç–µ–π –∏–∑ –õ–µ–Ω—Ç—ã.—Ä—É, —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ [Natasha](https://github.com/natasha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a9763a-a5c5-4079-8571-c19a25f361cd",
   "metadata": {},
   "source": [
    "## –î–∞—Ç–∞—Å–µ—Ç Nerus –∏ –¥–∞—Ä—ã torch.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba8e9e-2a5e-40a8-b03c-95ed7d322c0e",
   "metadata": {},
   "source": [
    "–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –æ—Ç–µ–¥–ª—å–Ω–æ –∞—Ä—Ö–∏–≤—á–∏–∫–æ–º: [link](https://github.com/natasha/nerus#:~:text=Download-,nerus_lenta.conllu.gz,-~2GB%2C%20~700K%20texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea819a-ff00-4005-8355-95d310e68c42",
   "metadata": {},
   "source": [
    "–í–Ω—Ç—É—Ä–∏ —á—Ç–æ-—Ç–æ —Ç–∞–∫–æ–µ:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcaf63-1a95-4f0b-a0a7-def85fb2eff5",
   "metadata": {},
   "source": [
    "```bash\n",
    "friday@fridaydevice:~/HSE/HSE-NLP$ gunzip -c nerus_lenta.conllu.gz | head\n",
    "# newdoc id = 0\n",
    "# sent_id = 0_0\n",
    "# text = –í–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä –ø–æ —Å–æ—Ü–∏–∞–ª—å–Ω—ã–º –≤–æ–ø—Ä–æ—Å–∞–º –¢–∞—Ç—å—è–Ω–∞ –ì–æ–ª–∏–∫–æ–≤–∞ —Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞, –≤ –∫–∞–∫–∏—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö –†–æ—Å—Å–∏–∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞–∏–±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∞—è —Å–º–µ—Ä—Ç–Ω–æ—Å—Ç—å –æ—Ç —Ä–∞–∫–∞, —Å–æ–æ–±—â–∞–µ—Ç –†–ò–ê –ù–æ–≤–æ—Å—Ç–∏.\n",
    "1\t–í–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä\t_\tNOUN\t_\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\t7\tnsubj\t_\tTag=O\n",
    "2\t–ø–æ\t_\tADP\t_\t_\t4\tcase\t_\tTag=O\n",
    "3\t—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º\t_\tADJ\t_\tCase=Dat|Degree=Pos|Number=Plur4amod\t_\tTag=O\n",
    "4\t–≤–æ–ø—Ä–æ—Å–∞–º\t_\tNOUN\t_\tAnimacy=Inan|Case=Dat|Gender=Masc|Number=Plur\t1\tnmod\t_\tTag=O\n",
    "5\t–¢–∞—Ç—å—è–Ω–∞\t_\tPROPN\t_\tAnimacy=Anim|Case=Nom|Gender=Fem|Number=Sing\t1\tappos\t_\tTag=B-PER\n",
    "6\t–ì–æ–ª–∏–∫–æ–≤–∞\t_\tPROPN\t_\tAnimacy=Anim|Case=Nom|Gender=Fem|Number=Sing\t5\tflat:name\t_\tTag=I-PER\n",
    "7\t—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞\t_\tVERB\t_\tAspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act\t0\troot\t_\tTag=O\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19012e6-f504-40c2-86ee-acec3432fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NERUS = './nerus_lenta.conllu.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471beb6-50c5-4696-9868-5f6c16386e3f",
   "metadata": {},
   "source": [
    "–ê–≤—Ç–æ—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å–¥–µ–ª–∞–ª–∏ —É–¥–æ–±–Ω–æ–µ API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç—Ç–∏–º —Ñ–∞–π–ª–∏–∫–æ–º, –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a486bec4-c60c-445c-8500-38833be648cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerus import load_nerus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480c1d2-32c4-4385-8b8e-bd22cacb6472",
   "metadata": {},
   "source": [
    "–ê –µ—â—ë –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–∞–≥–∏—é RusVectores, –∫–æ—Ç–æ—Ä—É—é –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å—Ç—ç–º–º–∏–Ω–≥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ab3242-54db-40b1-b8bd-eed24e103f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the model...\n",
      "Processing input...\n"
     ]
    }
   ],
   "source": [
    "from ufal.udpipe import Model, Pipeline\n",
    "import webvectors.preprocessing.rus_preprocessing_udpipe as udpipe_preproc # cloned from https://github.com/akutuzov/webvectors/blob/master/preprocessing/rus_preprocessing_udpipe.py\n",
    "\n",
    "UDPIPE_MODEL = 'udpipe_syntagrus.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1da9c3b-c92c-4582-8323-19345d325e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    def __init__(self,modelfile):\n",
    "        self.stemming_model = Model.load(modelfile)\n",
    "        self.process_pipeline = Pipeline(self.stemming_model, 'tokenize',Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
    "        \n",
    "    def stem_word(self, word):\n",
    "        return udpipe_preproc.process(\n",
    "            self.process_pipeline, text=udpipe_preproc.unify_sym(word), keep_punct=True, keep_pos=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67f3e0-e4a3-4bce-b957-b7f22352a4f6",
   "metadata": {},
   "source": [
    "> –ü—Ä–∏–º–µ—Ä —Å—Ç–µ–º–∏–Ω–≥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f889428-d983-4045-9d82-d58c673e8afc",
   "metadata": {},
   "source": [
    "–° –ø–æ–º–æ—â—å—é API –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –≤ –æ–¥–Ω–æ —Å—Ç—Ä–æ—á–∫—É –∏ –ø–æ–ª—É—á–∏—Ç—å –∏—Ç–µ—Ä–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ—Ç–¥–∞–≤–∞—Ç—å —Å—Ç–∞—Ç—å–∏ –∏ –∏—Ö —Ä–∞–∑–º–µ—Ç–∫—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841273de-8b08-41e2-a262-455eec3a2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_nerus(NERUS)\n",
    "doc = next(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb21c0e-a83a-4815-86dc-26a5d51fd65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä -> ['–≤–∏—Ü–µ-–ø—Ä–µ–º—å–µ—Ä']\n",
      "–ø–æ -> ['–ø–æ']\n",
      "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–º -> ['—Å–æ—Ü–∏–∞–ª—å–Ω—ã–π']\n",
      "–≤–æ–ø—Ä–æ—Å–∞–º -> ['–≤–æ–ø—Ä–æ—Å']\n",
      "–¢–∞—Ç—å—è–Ω–∞ -> ['—Ç–∞—Ç—å—è–Ω–∞']\n",
      "–ì–æ–ª–∏–∫–æ–≤–∞ -> ['–≥–æ–ª–∏–∫–æ–≤–∞']\n",
      "—Ä–∞—Å—Å–∫–∞–∑–∞–ª–∞ -> ['—Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å']\n",
      ", -> [',']\n",
      "–≤ -> ['–≤']\n",
      "–∫–∞–∫–∏—Ö -> ['–∫–∞–∫–æ–π']\n"
     ]
    }
   ],
   "source": [
    "docs = load_nerus(NERUS)\n",
    "doc = next(docs)\n",
    "stemmer = Stemmer(UDPIPE_MODEL)\n",
    "for i in range(10):\n",
    "    text = doc.sents[0].tokens[i].text\n",
    "    res = udpipe_preproc.process(stemmer.process_pipeline, text=udpipe_preproc.unify_sym(text), keep_punct=True, keep_pos=False) \n",
    "    print(f\"{text} -> {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297852b-b9be-4d2d-8d0a-e1ae41c511b1",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º—ë–º –∫—É—Å–æ—á–µ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ä–∞—Å–ø–∏–ª–∏–º –µ–≥–æ –Ω–∞ train/test/validation –∏ –∑–∞–ø–∏—à–µ–º –∏—Ö –≤ `tsv` —Ñ–∞–π–ª–∏–∫–∏, –∞ –µ—â—ë –ø—Ä–∏–º–µ–Ω–∏–º —Å—Ç—ç–º–º–∏–Ω–≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d24d38f-2fba-4a46-8d8e-0c71468b5ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dataset(path, stemmer, train_num = 5_000, val_num = 500, test_num = 1000):\n",
    "    docs = load_nerus(path)\n",
    "    for num, file in [(train_num, f\"ner_train_{train_num}.tsv\"), (val_num,  f\"ner_val_{val_num}.tsv\"), (test_num,  f\"ner_test_{test_num}.tsv\")]:\n",
    "        with open (file, 'w') as out_file:\n",
    "            tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "            while (num):\n",
    "                doc = next(docs)\n",
    "                for sent in doc.sents:\n",
    "                    for token in sent.tokens:\n",
    "                        stem_word = stemmer.stem_word(token.text)\n",
    "                        if stem_word:\n",
    "                            # ignore symbols, emojies and foereign languages \n",
    "                            text = stem_word[0]\n",
    "                            tsv_writer.writerow(\n",
    "                                [text,  token.tag]\n",
    "                            )\n",
    "                        \n",
    "                tsv_writer.writerow([]) # empty line between documents\n",
    "                num -= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65127c4-762d-4391-a0ae-8b65b0e28017",
   "metadata": {},
   "source": [
    "–ó–∞–ø—É—Å–∫–∞–µ–º..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa18bce-bae3-4642-92c1-af14c52def22",
   "metadata": {},
   "source": [
    "( –∏–ª–∏ –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–æ–ª–≥–æ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc07d679-f48c-4888-be89-6dfed0e474bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = Stemmer(UDPIPE_MODEL)\n",
    "# dump_dataset(path=NERUS, stemmer=stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683049f9-8af8-46c1-98cb-12810d3b83a5",
   "metadata": {},
   "source": [
    "–ê —Ç–µ–ø–µ—Ä—å –ø—Ä–∏–º–µ–Ω–∏–º –º–∞–≥–∏—é TorchText, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å —É–¥–æ–±–Ω—ã–π DataLoader. –í —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏ TorchText –µ—Å—Ç—å —É–¥–æ–±–Ω—ã–π `SequenceTaggingDataset`, –∫–æ—Ç–æ—Ä—ã–π —Å–¥–µ–ª–∞–µ—Ç –Ω–∞–º –∏–∑ —Ñ–∞–π–ª–∏–∫–æ–≤ DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "238ee129-daf1-4aec-b19f-7956885b4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_field = Field(lower=True)\n",
    "tag_field = Field(unk_token=None)\n",
    "train_data, val_data, test_data = SequenceTaggingDataset.splits(\n",
    "    path='.',\n",
    "    train='ner_train_5000.tsv',\n",
    "    validation='ner_val_500.tsv',\n",
    "    test='ner_test_1000.tsv',\n",
    "    fields=(('word', word_field),  ('tag', tag_field))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9f153-509b-401d-98e9-294468d45b9b",
   "metadata": {},
   "source": [
    "–ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π 2 —Å–ø–∏—Å–∫–∞: \n",
    "* —Å–ø–∏—Å–æ–∫ —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ —Å—Ç–∞—Ç—å–∏ (–∏ –∑–Ω–∞–∫–∞–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏)\n",
    "* —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–º\n",
    "\n",
    "–ü—Ä–∏ —ç—Ç–æ–º –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç - –æ—Ç–¥–µ–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç–Ω–∞—è —Å—Ç–∞—Ç—å—è –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞: `SequenceTaggingDataset` —É–º–µ–µ—Ç —Ä–∞–∑–±–∏–≤–∞—Ç—å –ø–æ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–µ, –∫–æ—Ç–æ—Ä—É—é –º—ã –æ—Å—Ç–∞–≤–∏–ª–∏ –º–µ–∂–¥—É —Å—Ç–∞—Ç—å—è–º–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3912604a-34fe-4505-8aad-1a5b1b02fd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([['–∂–∏—Ç–µ–ª—å–Ω–∏—Ü–∞', '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π', '–≥–æ—Ä–æ–¥', '–æ—É–∏–Ω–≥—Å', '–º–∏–ª—Å', ',', '—à—Ç–∞—Ç', '–º—ç—Ä–∏–ª–µ–Ω–¥', ',', '–≤—ã–∏–≥—Ä—ã–≤–∞—Ç—å', '–¥–∂–µ–∫–ø–æ—Ç', '–≤', '–Ω–µ—Å–∫–æ–ª—å–∫–æ', '—Ç—ã—Å—è—á–∞', '–¥–æ–ª–ª–∞—Ä', '.', '–∫–∞–∫', '—Å–æ–æ–±—â–∞—Ç—å', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π', '–ø–æ—Ä—Ç–∞–ª', 'upi', ',', '–æ–Ω–∞', '–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç—å', '–∑–∞', '—ç—Ç–æ', '–±–µ—Å—Å–æ–Ω–Ω–∏—Ü–∞', '.', '—Ä–∞–±–æ—Ç–∞—Ç—å', '–º–µ–¥—Å–µ—Å—Ç—Ä–∞', '72-–ª–µ—Ç–Ω—è–µ', '–∂–µ–Ω—â–∏–Ω–∞', '—Ä–µ—à–∞—Ç—å', '–ª–æ–∂–∏—Ç—å—Å—è', '—Ä–∞–Ω–æ', '–ø–µ—Ä–µ–¥', '–¥–æ–ª–≥–∏–π', '—Å–º–µ–Ω–∞', '–≤', '–±–æ–ª—å–Ω–∏—Ü–∞', ',', '–Ω–æ', '–≤', '–æ–Ω–∞', '–Ω–µ', '–≤—ã—Ö–æ–¥–∏—Ç—å', '.', '\"\"\"\"', '—è', '–ø–æ—Å—Ç–æ—è–Ω–Ω–æ', '—Å–º–æ—Ç—Ä–µ—Ç—å', '–Ω–∞', '—á–∞—Å', '–∏', '–±–µ—Å–∏—Ç—å—Å—è', ',', '—á—Ç–æ', '–Ω–∏–∫–∞–∫', '–Ω–µ', '–º–æ—á—å', '–∑–∞—Å—ã–ø–∞—Ç—å', '.', '–ø–æ—Å–ª–µ–¥–Ω–∏–π', '–≤—Ä–µ–º—è', ',', '–∫–æ—Ç–æ—Ä—ã–π', '—è', '–∑–∞–ø–æ–º–Ω–∏—Ç—å', ',', '–±—ã—Ç—å', 'xx', ':', 'xx', '–≤–µ—á–µ—Ä', '\"\"\"\"', ',', '-', '—Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å', '–∞–º–µ—Ä–∏–∫–∞–Ω–∫–∞', '.', '–ø–æ', '–æ–Ω–∞', '—Å–ª–æ–≤–æ', ',', '—ç—Ç–æ—Ç', '—á–∏—Å–ª–æ', '–∑–∞–ø–∞—Å—Ç—å', '–æ–Ω–∞', '–≤', '–≥–æ–ª–æ–≤–∞', ',', '–ø–æ—ç—Ç–æ–º—É', '–Ω–∞', '—Å–ª–µ–¥—É—é—â–∏–π', '–ø–æ—Å–ª–µ', '—Å–º–µ–Ω–∞', '–¥–µ–Ω—å', '–æ–Ω–∞', '–æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å—Å—è', '–≤', '–º–∞–≥–∞–∑–∏–Ω', '–∑–∞', '–ª–æ—Ç–µ—Ä–µ–π–Ω—ã–π', '–±–∏–ª–µ—Ç', '.', '–∂–µ–Ω—â–∏–Ω–∞', '—Ä–µ—à–∞—Ç—å', '–ø–æ–∏–≥—Ä–∞—Ç—å', '–≤', '–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π', '—Å–∫–∞—á–∫–∞', '–∏', '—Å—Ç–∞–≤–∏—Ç—å', '–Ω–∞', '–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–π', '–ª–æ—à–∞–¥—å', '–ø–æ–¥', '–Ω–æ–º–µ—Ä', '–æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç—å', ',', '–ø—è—Ç—å', '–∏', '—à–µ—Å—Ç—å', '.', '–æ–Ω–∞', '—É–º–µ—Ç—å', '—É–≥–∞–¥—ã–≤–∞—Ç—å', '–≤—Å–µ', '–Ω–æ–º–µ—Ä', '–ø–æ–±–µ–¥–∏—Ç–µ–ª—å', '–∏', '—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è', '–æ–±–ª–∞–¥–∞—Ç–µ–ª—å–Ω–∏—Ü–∞', '–¥–∂–µ–∫–ø–æ—Ç', '–≤', 'xx', 'xxx', '–¥–æ–ª–ª–∞—Ä', '(', '885,3', '—Ç—ã—Å—è—á–∞', '—Ä—É–±–ª—å', ')', '.', '—Ä–∞–Ω–µ–µ', '—Å–æ–æ–±—â–∞—Ç—å', '–æ', '–∞–º–µ—Ä–∏–∫–∞–Ω–µ—Ü', ',', '–∫–æ—Ç–æ—Ä—ã–π', '—Å—Ä—ã–≤–∞—Ç—å', '–¥–∂–µ–∫–ø–æ—Ç', ',', '–ø–æ–¥—Ä–∞–∂–∞—Ç—å', '–≥–µ—Ä–æ–π', '–∫–Ω–∏–≥–∞', ',', '–ø–∏—Å–∞—Ç—å', '–¥—Ä—É–≥–æ–π', '.', '–ø–µ—Ä—Å–æ–Ω–∞–∂', '–∫–∞–∂–¥—ã–π', '—É—Ç—Ä–æ', '–ø–∏–ª–∞', '–∫–æ—Ñ–µ', '–≤', '—Ç–æ—Ä–≥–æ–≤—ã–π', '—Ü–µ–Ω—Ç—Ä', '–∏', '–ø–æ–∫—É–ø–∞—Ç—å', '–±–∏–ª–µ—Ç', '–º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π', '–ª–æ—Ç–µ—Ä–µ—è', '.', '—á–∏—Ç–∞—Ç–µ–ª—å', '–¥–µ–ª–∞—Ç—å', '—Ç–∞–∫', '–∂–µ', '–∏', '–≤—ã–∏–≥—Ä—ã–≤–∞—Ç—å', 'xx', '—Ç—ã—Å—è—á–∞', '–¥–æ–ª–ª–∞—Ä', '(', '3,3', '–º–∏–ª–ª–∏–æ–Ω', '—Ä—É–±–ª—å', ')', '.'], ['O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[333].__dict__.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ff321-d408-4daf-895e-3d16aa87fe50",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å —Å–æ—Å—Ç–∞–≤–∏–º —Å–ª–æ–≤–∞—Ä–∏ —Å–ª–æ–≤ –∏ —Ç–æ–∫–µ–Ω —Å –ø–æ–º–æ—â—å—é `Field` –∫–ª–∞—Å—Å–∞, –∞ –µ—â—ë —Å–æ—Ö—Ä–∞–Ω–∏–º –∏–Ω–¥–µ–∫—Å—ã \"–ø—É—Å—Ç–æ–≥–æ\" —Å–ª–æ–≤–∞ –∏ —Ç—ç–≥–∞. –≠—Ç–∏–º–∏ \"–ø—É—Å—Ç—ã–º–∏\" —Å–ª–æ–≤–∞–º–∏ –∏ —Ç—ç–≥–∞–º–∏ –±—É–¥—É—Ç \"–¥–æ–∑–∞–±–∏–≤–∞—Ç—å—Å—è\" –º–∞—Ç—Ä–∏—á–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞—Ç—á–µ, —á—Ç–æ–±—ã –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –±–∞—Ç—á–∞ –±—ã–ª –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02717a4f-ad4f-4e96-a01a-cd3c75b8ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert fields to vocabulary list\n",
    "min_word_freq = 3\n",
    "batch_size = 10\n",
    "word_field.build_vocab(train_data.word, min_freq=min_word_freq)\n",
    "tag_field.build_vocab(train_data.tag)\n",
    "\n",
    "# prepare padding index to be ignored during model training/evaluation\n",
    "word_pad_idx = word_field.vocab.stoi[word_field.pad_token]\n",
    "tag_pad_idx = tag_field.vocab.stoi[tag_field.pad_token]\n",
    "\n",
    "# # create iterator for batch input\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train_data, val_data, test_data),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffad9387-8ddd-4c53-81a1-223d7b4ae3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty word index: 1\n",
      "Empty tag index: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Empty word index: {word_pad_idx}\")\n",
    "print(f\"Empty tag index: {tag_pad_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d76ebf74-339c-436e-aa45-d7b6a82c0ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 5000 sentences\n",
      "Val set: 500 sentences\n",
      "Test set: 1000 sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {len(train_data)} sentences\")\n",
    "print(f\"Val set: {len(val_data)} sentences\")\n",
    "print(f\"Test set: {len(test_data)} sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d2b9b-2329-4b50-b5e1-7e83bb5a69e0",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å, —á—Ç–æ –≤ –±–∞—Ç—á–µ, –º–æ–∂–Ω–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç—Ä–æ–≤–∞—Ç—å –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–¥ –Ω–∏–∂–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b59c7665-7f7e-4eb4-82d6-810fdba390cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_iter:\n",
    "#     print(batch)\n",
    "#     print(batch.word)\n",
    "#     print(batch.tag)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63478f0-5fc3-4544-abda-4ae26e7c81b2",
   "metadata": {},
   "source": [
    "–û–±–µ—Ä–Ω—ë–º –≤—Å—ë –≤ –æ–¥–∏–Ω –∫–ª–∞—Å—Å, —á—Ç–æ–±—ã –±—ã–ª–æ –ø—Ä–æ—â–µ –µ–≥–æ –ø–µ—Ä–µ–∫–ª–∞–¥—ã–≤–∞—Ç—å —Ç—É–¥–∞-—Å—é–¥–∞ –≤–æ –≤—Ä–µ–º—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99986935-bfb7-4744-b795-306c111ab3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataIterator:\n",
    "    train_iter: BucketIterator\n",
    "    val_iter: BucketIterator\n",
    "    test_iter: BucketIterator\n",
    "    tag_pad_idx: int\n",
    "    word_pad_idx: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4a2f7-7ae1-4e82-bd4b-7bc63197a7c5",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c055df-f7bf-424b-ae1c-a300501f2ed9",
   "metadata": {},
   "source": [
    "–í —ç—Ç–æ—Ç —Ä–∞–∑  –Ω–∞—Ç—Ä–µ–Ω–∏—Ä—É–µ–º —Å–≤–æ–∏ —ç–º–±—ç–¥–∏–Ω–≥–∏ –∏ –∑–∞—Å—É–Ω–µ–º –∏—Ö –≤ bidirectional LSTM.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å–∫–∞ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑:\n",
    "1. Embedding —Å–ª–æ—è ([nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html))\n",
    "1. BiLSTM —Å–ª–æ—ë–≤ ([nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html))\n",
    "1. –õ–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d911696-7218-4967-a543-3f432767dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, lstm_layers,\n",
    "               emb_dropout, lstm_dropout, fc_dropout, word_pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # LAYER 1: Embedding layer\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=input_dim, \n",
    "            embedding_dim=embedding_dim, \n",
    "            padding_idx=word_pad_idx\n",
    "        )\n",
    "        self.emb_dropout = nn.Dropout(emb_dropout) # TODO: we can add dropout in v2\n",
    "        # LAYER 2: BiLSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=lstm_dropout if lstm_layers > 1 else 0\n",
    "        )\n",
    "        # LAYER 3: Fully-connected layer\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # times 2 for bidirectional\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # sentence = [sentence length, batch size]\n",
    "        # embedding_out = [sentence length, batch size, embedding dim]\n",
    "        embedding_out = self.emb_dropout(self.embedding(sentence))\n",
    "        # lstm_out = [sentence length, batch size, hidden dim * 2]\n",
    "        lstm_out, _ = self.lstm(embedding_out)\n",
    "        # ner_out = [sentence length, batch size, output dim]\n",
    "        ner_out = self.fc(self.fc_dropout(lstm_out))\n",
    "        return ner_out\n",
    "\n",
    "    def init_weights(self):\n",
    "        # to initialize all parameters from normal distribution\n",
    "        # helps with converging during training\n",
    "        for name, param in self.named_parameters():\n",
    "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "\n",
    "    def init_embeddings(self, word_pad_idx):\n",
    "        # initialize embedding for padding as zero\n",
    "        self.embedding.weight.data[word_pad_idx] = torch.zeros(self.embedding_dim)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aa5c6a9-2ccf-4f24-a973-e5a1dc8ae187",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = BiLSTM(\n",
    "    input_dim=len(word_field.vocab),\n",
    "    embedding_dim=120, # 300\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(tag_field.vocab),\n",
    "    lstm_layers=2,\n",
    "    emb_dropout=0.5,\n",
    "    lstm_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=word_pad_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c144e245-fec8-491e-a4e7-4b95b987e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,323,192 trainable parameters.\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(17730, 120, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (lstm): LSTM(120, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (fc_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bilstm.init_weights()\n",
    "bilstm.init_embeddings(word_pad_idx=word_pad_idx)\n",
    "print(f\"The model has {bilstm.count_parameters():,} trainable parameters.\")\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ca0d9-9838-4e99-8f11-3e592bd2a079",
   "metadata": {},
   "source": [
    "## –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb73a41-4706-4502-a7ba-7238d4ea5e35",
   "metadata": {},
   "source": [
    "–ù–∏–∂–µ –±—É–¥–µ—Ç –º–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª—å–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd49a9ed-402f-4d71-98ec-22a4f2db8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852bfbb-4fd8-4d64-9ee5-08fa7dfdaa33",
   "metadata": {},
   "source": [
    "(–•–æ—Ä–æ—à–æ, —á—Ç–æ cuda –æ—Ç–≤–∞–ª–∏–ª–∞—Å—å –ø–æ—Å–ª–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –∞ –Ω–µ –¥–æ üôÉ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c22b9b-ffb2-4a1e-b0ca-6f3e3d1a8c6c",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è, —á—Ç–æ —Å—á–∏—Ç–∞—Ç—å –≤—Ä–µ–º—è –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136d86ae-88ef-475e-8b3e-ecd5952084bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a6099-8e0a-4c21-985b-0791a4108ec4",
   "metadata": {},
   "source": [
    "–ú–µ—Ç—Ä–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—ã—á–Ω—É—é accuracy, –Ω–æ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ–∏—à–∫–∞–º–∏ –¥–ª—è —É—á—ë—Ç–∞ –ø–∞–¥–¥–∏–Ω–≥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dc776c3-498d-4b64-9cd9-1094439b2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y, device):\n",
    "    max_preds = preds.argmax(dim=1, keepdim=True).to(device)  # get the index of the max probability\n",
    "    non_pad_elements = (y != data.tag_pad_idx).nonzero().to(device)  # prepare masking for paddings\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements]).to(device)\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc444cd-4075-472a-9660-207503d68e4a",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏, –≤—Å—ë –¥–æ–≤–æ–ª—å–Ω–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb48e972-1c0e-4842-a322-887ebb1c1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, data, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    for batch in data.train_iter:\n",
    "        # text = [sent len, batch size]\n",
    "        text = batch.word.to(device)\n",
    "        # tags = [sent len, batch size]\n",
    "        true_tags = batch.tag.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred_tags = model(text)\n",
    "        # to calculate the loss and accuracy, we flatten both prediction and true tags\n",
    "        # flatten pred_tags to [sent len, batch size, output dim]\n",
    "        pred_tags = pred_tags.view(-1, pred_tags.shape[-1])\n",
    "        # flatten true_tags to [sent len * batch size]\n",
    "        true_tags = true_tags.view(-1)\n",
    "        batch_loss = loss_fn(pred_tags, true_tags)\n",
    "        batch_acc = accuracy(pred_tags, true_tags, device)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        epoch_acc += batch_acc.item()\n",
    "    return epoch_loss / len(data.train_iter), epoch_acc / len(data.train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd8953-0640-463c-a59f-ab981454be31",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad32b69b-8423-4619-b282-a93616c4d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, loss_fn, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      # similar to epoch() but model is in evaluation mode and no backprop\n",
    "        for batch in iterator:\n",
    "            text = batch.word.to(device)\n",
    "            true_tags = batch.tag.to(device)\n",
    "            pred_tags = model(text)\n",
    "            pred_tags = pred_tags.view(-1, pred_tags.shape[-1])\n",
    "            true_tags = true_tags.view(-1)\n",
    "            batch_loss = loss_fn(pred_tags, true_tags)\n",
    "            batch_acc = accuracy(pred_tags, true_tags, device)\n",
    "            epoch_loss += batch_loss.item()\n",
    "            epoch_acc += batch_acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b97091-6477-495b-9aaa-3fd846e5379b",
   "metadata": {},
   "source": [
    "–ò, –Ω–∞–∫–æ–Ω–µ—Ü, —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc4daf94-a6e9-4057-bf1e-03b1ec751a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, loss_fn, device, n_epochs, n_val=5):\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss, train_acc = run_epoch(model, data, optimizer, loss_fn,device)\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        print(f\"Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "        print(f\"\\tTrn Loss: {train_loss:.3f} | Trn Acc: {train_acc * 100:.2f}%\")\n",
    "        if epoch % n_val == 0:\n",
    "            val_loss, val_acc = evaluate(model, data.val_iter, loss_fn, device)\n",
    "            print(f\"\\tVal Loss: {val_loss:.3f} | Val Acc: {val_acc * 100:.2f}%\")\n",
    "    test_loss, test_acc = evaluate(model, data.test_iter, loss_fn, device)\n",
    "    print(f\"Test Loss: {test_loss:.3f} |  Test Acc: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b9b95-80b3-480b-9e22-2b7c52d5350e",
   "metadata": {},
   "source": [
    "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7cb86a7-5ae6-46dd-a92b-819447ea1514",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=bilstm.to(device)\n",
    "data= DataIterator(train_iter=train_iter, val_iter=val_iter, test_iter=test_iter,tag_pad_idx=tag_pad_idx,word_pad_idx=word_pad_idx)\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "loss_fn=nn.CrossEntropyLoss(ignore_index=data.tag_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95f8a2a3-5f83-4e5f-b8f4-0f2d69b6dfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 16s\n",
      "\tTrn Loss: 0.313 | Trn Acc: 91.71%\n",
      "\tVal Loss: 0.118 | Val Acc: 96.33%\n",
      "Epoch: 02 | Epoch Time: 1m 14s\n",
      "\tTrn Loss: 0.100 | Trn Acc: 96.88%\n",
      "Epoch: 03 | Epoch Time: 1m 14s\n",
      "\tTrn Loss: 0.068 | Trn Acc: 97.86%\n",
      "Epoch: 04 | Epoch Time: 1m 15s\n",
      "\tTrn Loss: 0.055 | Trn Acc: 98.26%\n",
      "Epoch: 05 | Epoch Time: 1m 16s\n",
      "\tTrn Loss: 0.046 | Trn Acc: 98.53%\n",
      "Epoch: 06 | Epoch Time: 1m 17s\n",
      "\tTrn Loss: 0.041 | Trn Acc: 98.70%\n",
      "\tVal Loss: 0.060 | Val Acc: 98.14%\n",
      "Epoch: 07 | Epoch Time: 1m 18s\n",
      "\tTrn Loss: 0.035 | Trn Acc: 98.87%\n",
      "Epoch: 08 | Epoch Time: 1m 15s\n",
      "\tTrn Loss: 0.032 | Trn Acc: 98.95%\n",
      "Epoch: 09 | Epoch Time: 1m 15s\n",
      "\tTrn Loss: 0.029 | Trn Acc: 99.06%\n",
      "Epoch: 10 | Epoch Time: 1m 16s\n",
      "\tTrn Loss: 0.027 | Trn Acc: 99.13%\n",
      "Test Loss: 0.075 |  Test Acc: 97.93%\n"
     ]
    }
   ],
   "source": [
    "train(model, data, optimizer, loss_fn, device, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f409ba4-728c-458a-95a4-7a5a0d1eb2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ner-bilstm.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e540efe-4636-4d1f-87eb-d3394c0e7964",
   "metadata": {},
   "source": [
    "–ö–∞–∂–µ—Ç—Å—è, —á—Ç–æ-—Ç–æ –¥–∞–∂–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ü§ì –¢–µ—Å—Ç–æ–≤–∞—è accuracy 97.93% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
